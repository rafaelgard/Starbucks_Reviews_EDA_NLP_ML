{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rafaelgardel/starbucks-reviews-eda-nlp-and-ml-with-79-acc?scriptVersionId=144903490\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"\"Importing the libraries\"\n\nimport pandas as pd\nimport numpy as np\nimport nltk\n!pip install -U spacy\nimport spacy\nspacy.cli.download(\"en_core_web_sm\")\nimport string\nimport plotly.express as px\nfrom joblib import dump, load\nfrom stop_words import get_stop_words\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom wordcloud import WordCloud, ImageColorGenerator\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom scipy.stats import pearsonr\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nimport seaborn as sns\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T21:10:02.442807Z","iopub.execute_input":"2023-10-01T21:10:02.443525Z","iopub.status.idle":"2023-10-01T21:10:22.882567Z","shell.execute_reply.started":"2023-10-01T21:10:02.443491Z","shell.execute_reply":"2023-10-01T21:10:22.881329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Importing and Preprocessing the Data","metadata":{"execution":{"iopub.status.busy":"2023-09-30T15:14:55.240491Z","iopub.execute_input":"2023-09-30T15:14:55.240905Z","iopub.status.idle":"2023-09-30T15:14:55.246174Z","shell.execute_reply.started":"2023-09-30T15:14:55.240873Z","shell.execute_reply":"2023-09-30T15:14:55.24495Z"}}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/starbucks-reviews-dataset/reviews_data.csv')\n\ndef lemmatize_words(text, nlp):\n    \"Lemmatizes a list of words.\"\n\n    doc = nlp(text)\n\n    lemmatized_words = [token.lemma_ for token in doc]\n\n    return lemmatized_words\n\ndef remove_punctuation_and_digits(review):\n    '''Remove the punctuation and the digits from the review'''\n    \n    review = str(review)\n    review = \"\".join(\n        [char for char in review if char not in string.punctuation and char not in string.digits])\n    return review\n\ndf = df[['Rating', 'Review']]\n\n# Only rows where Rating and Review are not null will be considered.\ndf=df[(df['Rating'].isna()==False) & (df['Review'].isna()==False)]\n\ndf['Rating'] = df['Rating'].astype(int)\ndf['Review'] = df['Review'].astype('str')\n\n# Convert all comments to lowercase.\ndf['Review'] = df['Review'].str.lower()\n\n# Remove the punctuation and the digits from the review\ndf['Review'] = df['Review'].apply(lambda x: remove_punctuation_and_digits(x))\n\n# Lemmatizes the Review column\nnlp = spacy.load(\"en_core_web_sm\")\n\ndf['Review'] = df['Review'].apply(\n    lambda x: \" \".join(lemmatize_words(x, nlp)))\n\ndef get_sentiment(column):\n    '''Get the sentiment from the review'''\n    \n    sia = SentimentIntensityAnalyzer()\n        \n    column_polarity_scores = [sia.polarity_scores(text) for text in column]\n    column_sentiment_scores = []\n\n    for index, scores in enumerate(column_polarity_scores):\n        \n        if scores['pos']>scores['neg'] + scores['neu']:\n            pol = 'Positive'\n            \n        elif scores['neg']>scores['pos'] + scores['neu']:\n            pol = 'Negative'\n            \n        else:\n            pol = 'Neutral'\n            \n        column_sentiment_scores.append(pol)\n        \n    return column_sentiment_scores\n\ndf['Sentiment'] = get_sentiment(df['Review'])\n\ndf.drop_duplicates(keep='last', inplace=True, ignore_index=True)\n\ndf.reset_index()\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:22.885089Z","iopub.execute_input":"2023-10-01T21:10:22.885535Z","iopub.status.idle":"2023-10-01T21:10:38.174353Z","shell.execute_reply.started":"2023-10-01T21:10:22.885492Z","shell.execute_reply":"2023-10-01T21:10:38.173529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Evaluating the data","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Assessing data distribution","metadata":{}},{"cell_type":"code","source":"df_grouped = df.groupby('Rating').count()['Review'].reset_index()\ndf_grouped['Rating'] = df_grouped['Rating'].astype(str)\n\nfig = px.bar(df_grouped, x='Rating', y='Review', text='Review', color='Rating', title='Count of Reviews by Rating')\nfig.update_traces(texttemplate='%{text}', textposition='outside')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:38.175821Z","iopub.execute_input":"2023-10-01T21:10:38.176096Z","iopub.status.idle":"2023-10-01T21:10:38.25945Z","shell.execute_reply.started":"2023-10-01T21:10:38.176072Z","shell.execute_reply":"2023-10-01T21:10:38.258414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that most of the reviews have a rating equal to 1, indicating a highly imbalanced dataset.","metadata":{}},{"cell_type":"code","source":"# Evaluating the correlation between the number of words in the comment and the Rating.\ndf['Qty_of_words'] = [len(x) for x in df['Review']]\n\nprint(df[['Rating', 'Qty_of_words']].corr().round(2),'\\n')\n\ncorrelation, p_value = pearsonr(df['Qty_of_words'], df['Rating'])\n\nprint(f'correlation between Qty_of_words and Rating: {correlation:.2f}, p-value: {p_value:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:38.262551Z","iopub.execute_input":"2023-10-01T21:10:38.263095Z","iopub.status.idle":"2023-10-01T21:10:38.278473Z","shell.execute_reply.started":"2023-10-01T21:10:38.263066Z","shell.execute_reply":"2023-10-01T21:10:38.277333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Pearson correlation analysis revealed a statistically significant negative relationship (correlation of approximately -0.32, p-value < 0.0001) between the number of words in a dataset ('Qty_of_words') and the associated rating ('Rating'). This suggests that, on average, as the number of words increases, the rating tends to decrease, which could be a relevant finding for understanding the dataset dynamics and influencing future analyses or decision-making.","metadata":{}},{"cell_type":"code","source":"# Evaluating the relationship between the number of words, Rating, and the Rating.\npx.scatter(df, x='Qty_of_words', y='Rating', color=\"Rating\",\n           color_continuous_scale=[\"red\", \"green\", \"blue\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:38.279937Z","iopub.execute_input":"2023-10-01T21:10:38.280975Z","iopub.status.idle":"2023-10-01T21:10:38.38749Z","shell.execute_reply.started":"2023-10-01T21:10:38.280944Z","shell.execute_reply":"2023-10-01T21:10:38.386705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the relationship between the number of words and the Rating.\npx.histogram(df.sort_values(by='Rating'), x='Qty_of_words', color=\"Rating\", facet_row='Rating')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:38.388651Z","iopub.execute_input":"2023-10-01T21:10:38.388929Z","iopub.status.idle":"2023-10-01T21:10:38.530243Z","shell.execute_reply.started":"2023-10-01T21:10:38.388904Z","shell.execute_reply":"2023-10-01T21:10:38.529549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(df, x='Rating', size='Qty_of_words',\n              y='Qty_of_words', color='Rating')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:38.53145Z","iopub.execute_input":"2023-10-01T21:10:38.531947Z","iopub.status.idle":"2023-10-01T21:10:38.594929Z","shell.execute_reply.started":"2023-10-01T21:10:38.531921Z","shell.execute_reply":"2023-10-01T21:10:38.593941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating the relationship between the number of words and the Rating.\npx.histogram(df.sort_values(by='Rating'), x='Qty_of_words', color=\"Sentiment\", facet_row='Rating')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:38.596111Z","iopub.execute_input":"2023-10-01T21:10:38.596422Z","iopub.status.idle":"2023-10-01T21:10:38.699438Z","shell.execute_reply.started":"2023-10-01T21:10:38.596397Z","shell.execute_reply":"2023-10-01T21:10:38.698335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2. Evaluating the vocabulary","metadata":{}},{"cell_type":"code","source":"stopWords = nltk.corpus.stopwords.words('english')\nvectorizer = CountVectorizer(stop_words=stopWords)\nbag_of_words = vectorizer.fit_transform(df['Review'].tolist())\n\nprint(f'Vocabulary size {len(vectorizer.vocabulary_)}\\n')\n\n# the 5 elements with the highest appearances\nhighest_appearances = dict(sorted(\n    vectorizer.vocabulary_.items(), key=lambda item: item[1], reverse=True)[:5])\n\nprint(\"5 elements with the highest appearances:\")\nprint(highest_appearances, '\\n')\n\nprint(f'Appearances per word: {vectorizer.vocabulary_}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:38.700528Z","iopub.execute_input":"2023-10-01T21:10:38.700904Z","iopub.status.idle":"2023-10-01T21:10:38.794647Z","shell.execute_reply.started":"2023-10-01T21:10:38.700878Z","shell.execute_reply":"2023-10-01T21:10:38.793845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combining all comments to build the word cloud.\nall_comments = \"\".join(comment for comment in df['Review'])\n\n# Instantiating the word cloud.\nwordcloud = WordCloud(stopwords=stopWords,\n                      background_color='black', width=1600,\n                      height=800, max_words=1000,  max_font_size=500,\n                      min_font_size=1).generate(all_comments)  # mask=mask,\n\n# Whe wordcloud\nfig, ax = plt.subplots(figsize=(16, 8))\nax.imshow(wordcloud, interpolation='bilinear')\nax.set_axis_off()\nplt.imshow(wordcloud)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:38.797016Z","iopub.execute_input":"2023-10-01T21:10:38.797672Z","iopub.status.idle":"2023-10-01T21:10:49.985673Z","shell.execute_reply.started":"2023-10-01T21:10:38.797643Z","shell.execute_reply":"2023-10-01T21:10:49.984642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Training the Models","metadata":{}},{"cell_type":"markdown","source":"Testing various models while simultaneously performing feature selection (ANOVA F-value) with varying numbers of features (words) is a valuable approach. It helps answer important questions such as whether the variation in the number of features affects the results, which model performs best, what its accuracy is, and what the ideal number of words is. This systematic analysis will allow you to identify the most effective model, assess its accuracy, and determine the optimal number of words for your specific dataset and task, ultimately leading to more informed decisions in your data analysis process.","metadata":{"execution":{"iopub.status.busy":"2023-10-01T19:23:47.291378Z","iopub.execute_input":"2023-10-01T19:23:47.291676Z","iopub.status.idle":"2023-10-01T19:23:47.299238Z","shell.execute_reply.started":"2023-10-01T19:23:47.291651Z","shell.execute_reply":"2023-10-01T19:23:47.298125Z"}}},{"cell_type":"code","source":"models={\n    'AdaBoostClassifier': AdaBoostClassifier(),\n    'LogisticRegression': LogisticRegression(),\n    'RidgeClassifier': RidgeClassifier(),\n    'RandomForestClassifier': RandomForestClassifier(),\n    'DecisionTreeClassifier': DecisionTreeClassifier(),\n    'ExtraTreesClassifier': ExtraTreesClassifier(),\n    'GaussianNB': GaussianNB(),\n    'BernoulliNB': BernoulliNB(),\n    'MultinomialNB': MultinomialNB(),\n    'SVC': SVC(),\n    'LinearSVC': LinearSVC(),\n    'KNeighborsClassifier': KNeighborsClassifier(),\n}\n\nresults = {'best_acuracy': -np.inf,\n           'best_model': 0,\n        'best_features' : np.zeros(df['Review'].shape[0]),\n        'best_acuracy_evolution' : [],\n        'n_features_evolution' : [],\n        'improvements' : []\n       }\n\nvectorizer = TfidfVectorizer(stop_words=stopWords, analyzer = 'word')\nX = vectorizer.fit_transform(df['Review']).toarray()\ny = df['Rating']\n\nfor n_features in np.arange(100, X.shape[1], 100):\n    \n    selector = SelectKBest(f_classif, k=n_features)\n    X_selected = selector.fit_transform(X, y)\n    \n    X_train, X_test, y_train, y_test=train_test_split(X_selected, y, test_size=0.2, stratify=y, random_state=30)\n    \n    improvement = False\n\n    for name, model in models.items():\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        \n        if accuracy>results['best_acuracy']:\n            improvement=True\n            results['improvements'].append(improvement)\n            results['best_acuracy'] = accuracy\n            results['best_model'] = model\n            results['best_features'] = X_selected\n            results['best_acuracy_evolution'].append(results['best_acuracy'])\n            results['n_features_evolution'].append(n_features)\n            \n    if improvement:\n        print(f'n_features: {n_features}:{round(n_features/X.shape[1],2)} ')\n        print('Accuracy score of best model:', results['best_acuracy'],'\\n')\n    \n    else:        \n        results['improvements'].append(improvement)\n        results['n_features_evolution'].append(n_features)\n        results['best_acuracy_evolution'].append(results['best_acuracy'])\n        \n        print(f'n_features: {n_features}:{round(n_features/X.shape[1],2)} ')\n        print('Best accuracy not improved', results['best_acuracy'],'\\n')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:10:49.987307Z","iopub.execute_input":"2023-10-01T21:10:49.987679Z","iopub.status.idle":"2023-10-01T21:13:12.941903Z","shell.execute_reply.started":"2023-10-01T21:10:49.987645Z","shell.execute_reply":"2023-10-01T21:13:12.94108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Please note in the following graph how the best accuracy evolved with changes in vocabulary size.","metadata":{}},{"cell_type":"code","source":"results_dataframe = pd.DataFrame(results['n_features_evolution'])\nresults_dataframe.columns = ['n_features_evolution']\nresults_dataframe['best_acuracy_evolution'] = results['best_acuracy_evolution']\nresults_dataframe['improvements'] = results['improvements']\n\npx.scatter(results_dataframe, x='n_features_evolution',\n           y='best_acuracy_evolution', \n           color='improvements')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:13:12.94338Z","iopub.execute_input":"2023-10-01T21:13:12.943969Z","iopub.status.idle":"2023-10-01T21:13:13.005251Z","shell.execute_reply.started":"2023-10-01T21:13:12.943938Z","shell.execute_reply":"2023-10-01T21:13:13.003978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qty_words_of_original_dataset = X.shape[1]\nnew_qty_words_dataset = results['best_features'].shape[1]\nreduction = qty_words_of_original_dataset-new_qty_words_dataset\n\nprint('Best model:', results['best_model'])\nprint('Best acuracy:', results['best_acuracy'])\nprint('Best number of features:', new_qty_words_dataset)\nprint('Number of droped features:',reduction)\nprint('Percentual droped:', str(round(reduction/qty_words_of_original_dataset,2)*100)+'%')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T21:13:13.00672Z","iopub.execute_input":"2023-10-01T21:13:13.007138Z","iopub.status.idle":"2023-10-01T21:13:13.0197Z","shell.execute_reply.started":"2023-10-01T21:13:13.007099Z","shell.execute_reply":"2023-10-01T21:13:13.018621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What's interesting about this result is how the performance improved after dropping 71% of the features (words)! Initially, it had an accuracy of 61%, but there was a gain of 10%. This result can potentially further improve with hyperparameter optimization for the model.","metadata":{}},{"cell_type":"markdown","source":"## 4. Conclusions and Future Work","metadata":{}},{"cell_type":"markdown","source":"- The best model generated was the SVC with an accuracy of 79%.\n- The feature selection phase was crucial in achieving this result.\n- With hyperparameter optimization, it can potentially improve further, but given the small and imbalanced dataset, overfitting should be carefully monitored.\n- It would be interesting to explore other techniques, such as using neural networks with TensorFlow.\n\nI hope this notebook has been useful! Best regards!","metadata":{}}]}